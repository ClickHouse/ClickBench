SELECT disk_name, formatReadableSize(sum(data_compressed_bytes) AS size) AS compressed, formatReadableSize(sum(data_uncompressed_bytes) AS usize) AS uncompressed, round(usize / size, 2) AS compr_rate, sum(rows) AS rows, count() AS part_count FROM system.parts WHERE (active = 1) AND (`table` = 'amazon_reviews') GROUP BY disk_name ORDER BY size DESC
SELECT product_title, review_headline FROM amazon.amazon_reviews ORDER BY helpful_votes DESC LIMIT 10
SELECT any(product_title), count() FROM amazon.amazon_reviews GROUP BY product_id ORDER BY 2 DESC LIMIT 10
SELECT toStartOfMonth(review_date) AS month, any(product_title), avg(star_rating) AS avg_stars FROM amazon.amazon_reviews GROUP BY month, product_id ORDER BY month DESC, product_id ASC LIMIT 20
SELECT sum(total_votes), product_category FROM amazon.amazon_reviews GROUP BY product_category ORDER BY 1 DESC
SELECT product_id, any(product_title), avg(star_rating), count() AS count FROM amazon.amazon_reviews WHERE position(review_body, 'awful') > 0 GROUP BY product_id ORDER BY count DESC LIMIT 50
SELECT product_id, any(product_title), avg(star_rating), count() AS count FROM amazon.amazon_reviews WHERE position(review_body, 'awesome') > 0 GROUP BY product_id ORDER BY count DESC LIMIT 50
SELECT machine_name, MIN(cpu) AS cpu_min, MAX(cpu) AS cpu_max, AVG(cpu) AS cpu_avg, MIN(net_in) AS net_in_min, MAX(net_in) AS net_in_max, AVG(net_in) AS net_in_avg, MIN(net_out) AS net_out_min, MAX(net_out) AS net_out_max, AVG(net_out) AS net_out_avg FROM (SELECT machine_name, COALESCE(cpu_user, 0.) AS cpu, COALESCE(bytes_in, 0.) AS net_in, COALESCE(bytes_out, 0.) AS net_out FROM mgbench.logs1 WHERE (machine_name IN ('anansi', 'aragog', 'urd')) AND (log_time >= toDateTime('2017-01-11 00:00:00'))) AS r GROUP BY machine_name
SELECT machine_name, log_time FROM mgbench.logs1 WHERE ((machine_name LIKE 'cslab%') OR (machine_name LIKE 'mslab%')) AND (load_one IS NULL) AND (log_time >= toDateTime('2017-01-10 00:00:00')) ORDER BY machine_name ASC, log_time ASC
SELECT dt, hr, AVG(load_fifteen) AS load_fifteen_avg, AVG(load_five) AS load_five_avg, AVG(load_one) AS load_one_avg, AVG(mem_free) AS mem_free_avg, AVG(swap_free) AS swap_free_avg FROM (SELECT CAST(log_time, 'DATE') AS dt, toHour(log_time) AS hr, load_fifteen, load_five, load_one, mem_free, swap_free FROM mgbench.logs1 WHERE (machine_name = 'babbage') AND (load_fifteen IS NOT NULL) AND (load_five IS NOT NULL) AND (load_one IS NOT NULL) AND (mem_free IS NOT NULL) AND (swap_free IS NOT NULL) AND (log_time >= toDateTime('2017-01-01 00:00:00'))) AS r GROUP BY dt, hr ORDER BY dt ASC, hr ASC
SELECT machine_name, COUNT(*) AS spikes FROM mgbench.logs1 WHERE (machine_group = 'Servers') AND (cpu_wio > 0.99) AND (log_time >= toDateTime('2016-12-01 00:00:00')) AND (log_time < toDateTime('2017-01-01 00:00:00')) GROUP BY machine_name ORDER BY spikes DESC LIMIT 10
SELECT machine_name, dt, MIN(mem_free) AS mem_free_min FROM (SELECT machine_name, CAST(log_time, 'DATE') AS dt, mem_free FROM mgbench.logs1 WHERE (machine_group = 'DMZ') AND (mem_free IS NOT NULL)) AS r GROUP BY machine_name, dt HAVING MIN(mem_free) < 10000 ORDER BY machine_name ASC, dt ASC
SELECT dt, hr, SUM(net_in) AS net_in_sum, SUM(net_out) AS net_out_sum, SUM(net_in) + SUM(net_out) AS both_sum FROM (SELECT CAST(log_time, 'DATE') AS dt, toHour(log_time) AS hr, COALESCE(bytes_in, 0.) / 1000000000. AS net_in, COALESCE(bytes_out, 0.) / 1000000000. AS net_out FROM mgbench.logs1 WHERE machine_name IN ('allsorts', 'andes', 'bigred', 'blackjack', 'bonbon', 'cadbury', 'chiclets', 'cotton', 'crows', 'dove', 'fireball', 'hearts', 'huey', 'lindt', 'milkduds', 'milkyway', 'mnm', 'necco', 'nerds', 'orbit', 'peeps', 'poprocks', 'razzles', 'runts', 'smarties', 'smuggler', 'spree', 'stride', 'tootsie', 'trident', 'wrigley', 'york')) AS r GROUP BY dt, hr ORDER BY both_sum DESC LIMIT 10
SELECT * FROM mgbench.logs2 WHERE (status_code >= 500) AND (log_time >= toDateTime('2012-12-18 00:00:00')) ORDER BY log_time ASC
SELECT * FROM mgbench.logs2 WHERE (status_code >= 200) AND (status_code < 300) AND (request LIKE '%/etc/passwd%') AND (log_time >= toDateTime('2012-05-06 00:00:00')) AND (log_time < toDateTime('2012-05-20 00:00:00'))
SELECT top_level, AVG(LENGTH(request) - LENGTH(REPLACE(request, '/', ''))) AS depth_avg FROM (SELECT substring(request, 1, len) AS top_level, request FROM (SELECT position(substring(request, 2), '/') AS len, request FROM mgbench.logs2 WHERE (status_code >= 200) AND (status_code < 300) AND (log_time >= toDateTime('2012-12-01 00:00:00'))) AS r WHERE len > 0) AS s WHERE top_level IN ('/about', '/courses', '/degrees', '/events', '/grad', '/industry', '/news', '/people', '/publications', '/research', '/teaching', '/ugrad') GROUP BY top_level ORDER BY top_level ASC
SELECT client_ip, COUNT(*) AS num_requests FROM mgbench.logs2 WHERE log_time >= toDateTime('2012-10-01 00:00:00') GROUP BY client_ip HAVING COUNT(*) >= 100000 ORDER BY num_requests DESC
SELECT dt, COUNTDistinct(client_ip) FROM (SELECT CAST(log_time, 'DATE') AS dt, client_ip FROM mgbench.logs2) AS r GROUP BY dt ORDER BY dt ASC
SELECT AVG(transfer) / 125000000. AS transfer_avg, MAX(transfer) / 125000000. AS transfer_max FROM (SELECT log_time, SUM(object_size) AS transfer FROM mgbench.logs2 GROUP BY log_time) AS r
SELECT * FROM mgbench.logs3 WHERE (event_type = 'temperature') AND (event_value <= 32.) AND (log_time >= '2019-11-29 17:00:00.000')
SELECT device_name, device_floor, COUNT(*) AS ct FROM mgbench.logs3 WHERE (event_type = 'door_open') AND (log_time >= '2019-06-01 00:00:00.000') GROUP BY device_name, device_floor ORDER BY ct DESC
WITH temperature AS (SELECT dt, device_name, device_type, device_floor FROM (SELECT dt, hr, device_name, device_type, device_floor, AVG(event_value) AS temperature_hourly_avg FROM (SELECT CAST(log_time, 'DATE') AS dt, toHour(log_time) AS hr, device_name, device_type, device_floor, event_value FROM mgbench.logs3 WHERE event_type = 'temperature') AS r GROUP BY dt, hr, device_name, device_type, device_floor) AS s GROUP BY dt, device_name, device_type, device_floor HAVING (MAX(temperature_hourly_avg) - MIN(temperature_hourly_avg)) >= 25.) SELECT DISTINCT device_name, device_type, device_floor, 'WINTER' FROM temperature WHERE (dt >= toDate('2018-12-01')) AND (dt < toDate('2019-03-01')) UNION DISTINCT SELECT DISTINCT device_name, device_type, device_floor, 'SUMMER' FROM temperature WHERE (dt >= toDate('2019-06-01')) AND (dt < toDate('2019-09-01'))
SELECT yr, mo, SUM(coffee_hourly_avg) AS coffee_monthly_sum, AVG(coffee_hourly_avg) AS coffee_monthly_avg, SUM(printer_hourly_avg) AS printer_monthly_sum, AVG(printer_hourly_avg) AS printer_monthly_avg, SUM(projector_hourly_avg) AS projector_monthly_sum, AVG(projector_hourly_avg) AS projector_monthly_avg, SUM(vending_hourly_avg) AS vending_monthly_sum, AVG(vending_hourly_avg) AS vending_monthly_avg FROM (SELECT dt, yr, mo, hr, AVG(coffee) AS coffee_hourly_avg, AVG(printer) AS printer_hourly_avg, AVG(projector) AS projector_hourly_avg, AVG(vending) AS vending_hourly_avg FROM (SELECT CAST(log_time, 'DATE') AS dt, toYear(log_time) AS yr, toMonth(log_time) AS mo, toHour(log_time) AS hr, multiIf(device_name LIKE 'coffee%', event_value, NULL) AS coffee, multiIf(device_name LIKE 'printer%', event_value, NULL) AS printer, multiIf(device_name LIKE 'projector%', event_value, NULL) AS projector, multiIf(device_name LIKE 'vending%', event_value, NULL) AS vending FROM mgbench.logs3 WHERE device_type = 'meter') AS r GROUP BY dt, yr, mo, hr) AS s GROUP BY yr, mo ORDER BY yr ASC, mo ASC
SELECT mcc, count() FROM geo.cell_towers GROUP BY mcc ORDER BY count() DESC LIMIT 10
SELECT radio, count() AS c FROM geo.cell_towers GROUP BY radio ORDER BY c DESC
SELECT count() FROM geo.cell_towers WHERE pointInPolygon((lon, lat), (SELECT * FROM geo.moscow))
SELECT formatReadableQuantity(count()) FROM covid.covid19
SELECT formatReadableQuantity(sum(new_confirmed)) FROM covid.covid19
SELECT AVG(new_confirmed) OVER (PARTITION BY location_key ORDER BY date ASC ROWS BETWEEN 2 PRECEDING AND 2 FOLLOWING) AS cases_smoothed, new_confirmed, location_key, date FROM covid.covid19
WITH latest_deaths_data AS (SELECT location_key, date, new_deceased, new_confirmed, ROW_NUMBER() OVER (PARTITION BY location_key ORDER BY date DESC) AS rn FROM covid.covid19) SELECT location_key, date, new_deceased, new_confirmed, rn FROM latest_deaths_data WHERE rn = 1
WITH confirmed_lag AS (SELECT *, lagInFrame(new_confirmed) OVER (PARTITION BY location_key ORDER BY date ASC) AS confirmed_previous_day FROM covid.covid19), confirmed_percent_change AS (SELECT *, COALESCE(ROUND(((new_confirmed - confirmed_previous_day) / confirmed_previous_day) * 100), 0) AS percent_change FROM confirmed_lag) SELECT date, new_confirmed, percent_change, multiIf(percent_change > 0, 'increase', percent_change = 0, 'no change', 'decrease') AS trend FROM confirmed_percent_change WHERE location_key = 'US_DC'
SELECT arrayJoin(NER) AS k, count() AS c FROM food.recipes GROUP BY k ORDER BY c DESC LIMIT 50
SELECT machine_name, MIN(cpu) AS cpu_min, MAX(cpu) AS cpu_max, AVG(cpu) AS cpu_avg, MIN(net_in) AS net_in_min, MAX(net_in) AS net_in_max, AVG(net_in) AS net_in_avg, MIN(net_out) AS net_out_min, MAX(net_out) AS net_out_max, AVG(net_out) AS net_out_avg FROM (SELECT machine_name, COALESCE(cpu_user, 0.) AS cpu, COALESCE(bytes_in, 0.) AS net_in, COALESCE(bytes_out, 0.) AS net_out FROM mgbench.logs1 WHERE (machine_name IN ('anansi', 'aragog', 'urd')) AND (log_time >= toDateTime('2017-01-11 00:00:00'))) AS r GROUP BY machine_name
SELECT library_name, license_type, license_path FROM system.licenses ORDER BY library_name ASC COLLATE 'en'
WITH states AS (SELECT month, uniqState(actor_login) AS uniq_users FROM git.github_events WHERE (repo_name LIKE 'ClickHouse%') AND (event_type = 'PullRequestEvent') GROUP BY toStartOfMonth(created_at) AS month ORDER BY month ASC) SELECT month, uniqMerge(uniq_users) OVER (ORDER BY month ASC) AS cul_users FROM states
SELECT month, arrayUniq(cul_users) AS cul_users, arrayUniq(uniq_users) AS uniq_users FROM (SELECT month, groupArrayDistinctArray(uniq_users) OVER (ORDER BY month ASC) AS cul_users, groupArrayDistinct(actor_login) AS uniq_users FROM git.github_events WHERE (repo_name LIKE 'ClickHouse%') AND (event_type = 'PullRequestEvent') GROUP BY toStartOfMonth(created_at) AS month ORDER BY month ASC)
SHOW TABLES FROM git
SELECT * FROM git.github_events WHERE repo_name LIKE '%/dbt-clickhouse' ORDER BY created_at ASC
SELECT * FROM git.github_events WHERE repo_name LIKE 'ClickHouse/dbt-clickhouse' ORDER BY created_at ASC
SELECT * FROM git.github_events LIMIT 1
SELECT author, toDate(day) AS day, any(day) OVER (PARTITION BY author ORDER BY day ASC ROWS BETWEEN 1 PRECEDING AND CURRENT ROW) AS previous_commit, dateDiff('day', previous_commit, day) AS day_diff, if(day_diff = 1, 1, 0) AS consecutive FROM (SELECT author, toStartOfDay(time) AS day FROM git.clickhouse_commits GROUP BY author, day ORDER BY author ASC, day ASC) LIMIT 10
WITH changes AS (SELECT path, commit_hash, max_time, type, num_added, num_deleted, sum(num_added - num_deleted) OVER (PARTITION BY path ORDER BY max_time ASC) AS current_size, if(current_size > 0, num_added / current_size, 0) AS percent_add, if(current_size > 0, num_deleted / current_size, 0) AS percent_delete FROM (SELECT path, max(time) AS max_time, commit_hash, any(lines_added) AS num_added, any(lines_deleted) AS num_deleted, any(change_type) AS type FROM git.clickhouse_file_changes WHERE (change_type IN ('Add', 'Modify')) AND (file_extension IN ('h', 'cpp', 'sql')) GROUP BY path, commit_hash ORDER BY path ASC, max_time ASC)), rewrites AS (SELECT *, any(max_time) OVER (PARTITION BY path ORDER BY max_time ASC ROWS BETWEEN 1 PRECEDING AND CURRENT ROW) AS previous_rewrite, dateDiff('day', previous_rewrite, max_time) AS rewrite_days FROM changes WHERE (type = 'Modify') AND (percent_add >= 0.5) AND (percent_delete >= 0.5) AND (current_size > 50)) SELECT avgIf(rewrite_days, rewrite_days > 0) AS avg_rewrite_time, quantilesTimingIf(0.5)(rewrite_days, rewrite_days > 0) AS half_life FROM rewrites
SELECT time, substring(commit_hash, 1, 11) AS commit, change_type, author, path, old_path, lines_added, lines_deleted, commit_message FROM git.clickhouse_file_changes WHERE path = 'src/Storages/StorageReplicatedMergeTree.cpp' ORDER BY time DESC LIMIT 10
SELECT author, toStartOfDay(time) AS day FROM git.clickhouse_commits GROUP BY author, day ORDER BY author ASC, day ASC LIMIT 10
SELECT hash, time FROM git.clickhouse_commits ORDER BY time DESC LIMIT 1
SELECT time, substring(commit_hash, 1, 11) AS commit, sign, line_number_old, line_number_new, author, line FROM git.clickhouse_line_changes WHERE path = 'src/Storages/StorageReplicatedMergeTree.cpp' ORDER BY line_number_new ASC LIMIT 10
SELECT path FROM (SELECT old_path AS path, max(time) AS last_time, 2 AS change_type FROM git.clickhouse_file_changes GROUP BY old_path UNION ALL SELECT path, max(time) AS last_time, argMax(change_type, time) AS change_type FROM git.clickhouse_file_changes GROUP BY path) GROUP BY path HAVING (argMax(change_type, last_time) != 2) AND (NOT match(path, '(^dbms/)|(^libs/)|(^tests/testflows/)|(^programs/server/store/)')) ORDER BY path ASC LIMIT 10
SELECT uniq(path) FROM (SELECT path FROM (SELECT old_path AS path, max(time) AS last_time, 2 AS change_type FROM git.clickhouse_file_changes GROUP BY old_path UNION ALL SELECT path, max(time) AS last_time, argMax(change_type, time) AS change_type FROM git.clickhouse_file_changes GROUP BY path) GROUP BY path HAVING (argMax(change_type, last_time) != 2) AND (NOT match(path, '(^dbms/)|(^libs/)|(^tests/testflows/)|(^programs/server/store/)')) ORDER BY path ASC)
SELECT change_type, path, old_path, time, commit_hash FROM git.clickhouse_file_changes WHERE (path = 'src/Functions/geometryFromColumn.h') OR (old_path = 'src/Functions/geometryFromColumn.h')
WITH current_files AS (SELECT path FROM (SELECT old_path AS path, max(time) AS last_time, 2 AS change_type FROM git.clickhouse_file_changes GROUP BY old_path UNION ALL SELECT path, max(time) AS last_time, argMax(change_type, time) AS change_type FROM git.clickhouse_file_changes GROUP BY path) GROUP BY path HAVING (argMax(change_type, last_time) != 2) AND (NOT match(path, '(^dbms/)|(^libs/)|(^tests/testflows/)|(^programs/server/store/)')) ORDER BY path ASC) SELECT path, sum(lines_added) + sum(lines_deleted) AS modifications FROM git.clickhouse_file_changes WHERE (path IN (current_files)) AND (file_extension IN ('h', 'cpp', 'sql')) GROUP BY path ORDER BY modifications DESC LIMIT 10
SELECT day_of_week, count() AS c FROM git.clickhouse_commits GROUP BY dayOfWeek(time) AS day_of_week
SELECT week, sum(lines_added) AS lines_added, sum(lines_deleted) AS lines_deleted, uniq(commit_hash) AS num_commits, uniq(author) AS authors FROM git.clickhouse_file_changes WHERE path LIKE 'src/Storages%' GROUP BY toStartOfWeek(time) AS week ORDER BY week ASC LIMIT 10
WITH current_files AS (SELECT path FROM (SELECT old_path AS path, max(time) AS last_time, 2 AS change_type FROM git.clickhouse_file_changes GROUP BY old_path UNION ALL SELECT path, max(time) AS last_time, argMax(change_type, time) AS change_type FROM git.clickhouse_file_changes GROUP BY path) GROUP BY path HAVING (argMax(change_type, last_time) != 2) AND (NOT match(path, '(^dbms/)|(^libs/)|(^tests/testflows/)|(^programs/server/store/)')) ORDER BY path ASC) SELECT path, uniq(author) AS num_authors FROM git.clickhouse_file_changes WHERE path IN (current_files) GROUP BY path ORDER BY num_authors DESC LIMIT 10
WITH current_files AS (SELECT path FROM (SELECT old_path AS path, max(time) AS last_time, 2 AS change_type FROM git.clickhouse_file_changes GROUP BY old_path UNION ALL SELECT path, max(time) AS last_time, argMax(change_type, time) AS change_type FROM git.clickhouse_file_changes GROUP BY path) GROUP BY path HAVING (argMax(change_type, last_time) != 2) AND (NOT match(path, '(^dbms/)|(^libs/)|(^tests/testflows/)|(^programs/server/store/)')) ORDER BY path ASC) SELECT any(path) AS file_path, line, max(time) AS latest_change, any(file_change_type) FROM git.clickhouse_line_changes WHERE path IN (current_files) GROUP BY line ORDER BY latest_change ASC LIMIT 10
WITH current_files AS (SELECT path FROM (SELECT old_path AS path, max(time) AS last_time, 2 AS change_type FROM git.clickhouse_file_changes GROUP BY old_path UNION ALL SELECT path, max(time) AS last_time, argMax(change_type, time) AS change_type FROM git.clickhouse_file_changes GROUP BY path) GROUP BY path HAVING (argMax(change_type, last_time) != 2) AND (NOT match(path, '(^dbms/)|(^libs/)|(^tests/testflows/)|(^programs/server/store/)')) ORDER BY path ASC) SELECT count() AS c, path, max(time) AS latest_change FROM git.clickhouse_file_changes WHERE path IN (current_files) GROUP BY path ORDER BY c DESC LIMIT 10
SELECT day, bar(docs_ratio * 1000, 0, 100, 100) AS bar FROM (SELECT day, countIf(file_extension IN ('h', 'cpp', 'sql')) AS code, countIf(file_extension = 'md') AS docs, docs / (code + docs) AS docs_ratio FROM git.clickhouse_line_changes WHERE (sign = 1) AND (file_extension IN ('h', 'cpp', 'sql', 'md')) GROUP BY dayOfMonth(time) AS day)
SELECT author, uniq(path) AS num_files FROM git.clickhouse_file_changes WHERE (change_type IN ('Add', 'Modify')) AND (file_extension IN ('h', 'cpp', 'sql')) GROUP BY author ORDER BY num_files DESC LIMIT 10
SELECT author, sum(num_files_commit) AS num_files FROM (SELECT author, commit_hash, uniq(path) AS num_files_commit, max(time) AS commit_time FROM git.clickhouse_file_changes WHERE (change_type IN ('Add', 'Modify')) AND (file_extension IN ('h', 'cpp', 'sql')) GROUP BY author, commit_hash ORDER BY author ASC, commit_time DESC LIMIT 3 BY author) GROUP BY author ORDER BY num_files DESC LIMIT 10
WITH current_files AS (SELECT path FROM (SELECT old_path AS path, max(time) AS last_time, 2 AS change_type FROM git.clickhouse_file_changes GROUP BY old_path UNION ALL SELECT path, max(time) AS last_time, argMax(change_type, time) AS change_type FROM git.clickhouse_file_changes GROUP BY path) GROUP BY path HAVING (argMax(change_type, last_time) != 2) AND (NOT match(path, '(^dbms/)|(^libs/)|(^tests/testflows/)|(^programs/server/store/)')) ORDER BY path ASC) SELECT path, count() AS c FROM git.clickhouse_file_changes WHERE (author = 'Alexey Milovidov') AND (path IN (current_files)) GROUP BY path ORDER BY c DESC LIMIT 10
SELECT base, count() AS c FROM git.clickhouse_file_changes WHERE (author = 'Alexey Milovidov') AND (file_extension IN ('h', 'cpp', 'sql')) GROUP BY basename(path) AS base ORDER BY c DESC LIMIT 10
WITH current_files AS (SELECT path FROM (SELECT old_path AS path, max(time) AS last_time, 2 AS change_type FROM git.clickhouse_file_changes GROUP BY old_path UNION ALL SELECT path, max(time) AS last_time, argMax(change_type, time) AS change_type FROM git.clickhouse_file_changes GROUP BY path) GROUP BY path HAVING (argMax(change_type, last_time) != 2) AND (NOT match(path, '(^dbms/)|(^libs/)|(^tests/testflows/)|(^programs/server/store/)')) ORDER BY path ASC) SELECT path, sum(lines_added) - sum(lines_deleted) AS num_lines, uniqExact(author) AS num_authors, num_lines / num_authors AS lines_author_ratio FROM git.clickhouse_file_changes WHERE path IN (current_files) GROUP BY path ORDER BY lines_author_ratio DESC LIMIT 10
WITH current_files AS (SELECT path FROM (SELECT old_path AS path, max(time) AS last_time, 2 AS change_type FROM git.clickhouse_file_changes GROUP BY old_path UNION ALL SELECT path, max(time) AS last_time, argMax(change_type, time) AS change_type FROM git.clickhouse_file_changes GROUP BY path) GROUP BY path HAVING (argMax(change_type, last_time) != 2) AND (NOT match(path, '(^dbms/)|(^libs/)|(^tests/testflows/)|(^programs/server/store/)')) ORDER BY path ASC) SELECT path, sum(lines_added) - sum(lines_deleted) AS num_lines, uniqExact(author) AS num_authors, num_lines / num_authors AS lines_author_ratio FROM git.clickhouse_file_changes WHERE (path IN (current_files)) AND (file_extension IN ('h', 'cpp', 'sql')) GROUP BY path ORDER BY lines_author_ratio DESC LIMIT 10
WITH current_files AS (SELECT path FROM (SELECT old_path AS path, max(time) AS last_time, 2 AS change_type FROM git.clickhouse_file_changes GROUP BY old_path UNION ALL SELECT path, max(time) AS last_time, argMax(change_type, time) AS change_type FROM git.clickhouse_file_changes GROUP BY path) GROUP BY path HAVING (argMax(change_type, last_time) != 2) AND (NOT match(path, '(^dbms/)|(^libs/)|(^tests/testflows/)|(^programs/server/store/)')) ORDER BY path ASC) SELECT min(time) AS min_date, path, sum(lines_added) - sum(lines_deleted) AS num_lines, uniqExact(author) AS num_authors, num_lines / num_authors AS lines_author_ratio FROM git.clickhouse_file_changes WHERE (path IN (current_files)) AND (file_extension IN ('h', 'cpp', 'sql')) GROUP BY path HAVING min_date <= (now() - toIntervalYear(1)) ORDER BY lines_author_ratio DESC LIMIT 10
SELECT dayOfWeek, uniq(commit_hash) AS commits, sum(lines_added) AS lines_added, sum(lines_deleted) AS lines_deleted FROM git.clickhouse_file_changes WHERE path LIKE 'src/Functions%' GROUP BY toDayOfWeek(time) AS dayOfWeek
SELECT hourOfDay, uniq(commit_hash) AS commits, sum(lines_added) AS lines_added, sum(lines_deleted) AS lines_deleted FROM git.clickhouse_file_changes WHERE path LIKE 'src/Functions%' GROUP BY toHour(time) AS hourOfDay
SELECT hourOfDay, bar(commits, 0, 400, 50) AS commits, bar(lines_added, 0, 30000, 50) AS lines_added, bar(lines_deleted, 0, 15000, 50) AS lines_deleted FROM (SELECT hourOfDay, uniq(commit_hash) AS commits, sum(lines_added) AS lines_added, sum(lines_deleted) AS lines_deleted FROM git.clickhouse_file_changes WHERE path LIKE 'src/Functions%' GROUP BY toHour(time) AS hourOfDay)
SELECT concat(prev_author, '(a)') AS add_author, concat(author, '(d)') AS delete_author, count() AS c FROM git.clickhouse_line_changes WHERE (sign = -1) AND (file_extension IN ('h', 'cpp')) AND (line_type NOT IN ('Punct', 'Empty')) AND (author != prev_author) AND (prev_author != '') GROUP BY prev_author, author ORDER BY c DESC LIMIT 1 BY prev_author LIMIT 100
SELECT day_of_week, author, count() AS c FROM git.clickhouse_commits GROUP BY dayOfWeek(time) AS day_of_week, author ORDER BY day_of_week ASC, c DESC LIMIT 1 BY day_of_week
SELECT day_of_week, author, count() AS c FROM git.clickhouse_commits WHERE time > (now() - toIntervalYear(1)) GROUP BY dayOfWeek(time) AS day_of_week, author ORDER BY day_of_week ASC, c DESC LIMIT 1 BY day_of_week
SELECT top_author.day_of_week, top_author.author, top_author.author_work / all_work.total_work AS top_author_percent FROM (SELECT day_of_week, author, sum(lines_added) + sum(lines_deleted) AS author_work FROM git.clickhouse_file_changes WHERE time > (now() - toIntervalYear(1)) GROUP BY author, dayOfWeek(time) AS day_of_week ORDER BY day_of_week ASC, author_work DESC LIMIT 1 BY day_of_week) AS top_author INNER JOIN (SELECT day_of_week, sum(lines_added) + sum(lines_deleted) AS total_work FROM git.clickhouse_file_changes WHERE time > (now() - toIntervalYear(1)) GROUP BY dayOfWeek(time) AS day_of_week) AS all_work USING (day_of_week)
WITH current_files AS (SELECT path FROM (SELECT old_path AS path, max(time) AS last_time, 2 AS change_type FROM git.clickhouse_file_changes GROUP BY old_path UNION ALL SELECT path, max(time) AS last_time, argMax(change_type, time) AS change_type FROM git.clickhouse_file_changes GROUP BY path) GROUP BY path HAVING (argMax(change_type, last_time) != 2) AND (NOT match(path, '(^dbms/)|(^libs/)|(^tests/testflows/)|(^programs/server/store/)')) ORDER BY path ASC) SELECT concat(root, '/', sub_folder) AS folder, round(avg(days_present)) AS avg_age_of_files, min(days_present) AS min_age_files, max(days_present) AS max_age_files, count() AS c FROM (SELECT path, dateDiff('day', min(time), toDate('2022-11-03')) AS days_present FROM git.clickhouse_file_changes WHERE (path IN (current_files)) AND (file_extension IN ('h', 'cpp', 'sql')) GROUP BY path) GROUP BY splitByChar('/', path)[1] AS root, splitByChar('/', path)[2] AS sub_folder ORDER BY root ASC, c DESC LIMIT 5 BY root
SELECT k, written_code.c, removed_code.c, removed_code.c / written_code.c AS remove_ratio FROM (SELECT author AS k, count() AS c FROM git.clickhouse_line_changes WHERE (sign = 1) AND (file_extension IN ('h', 'cpp')) AND (line_type NOT IN ('Punct', 'Empty')) GROUP BY k) AS written_code INNER JOIN (SELECT prev_author AS k, count() AS c FROM git.clickhouse_line_changes WHERE (sign = -1) AND (file_extension IN ('h', 'cpp')) AND (line_type NOT IN ('Punct', 'Empty')) AND (author != prev_author) GROUP BY k) AS removed_code USING (k) WHERE written_code.c > 1000 ORDER BY remove_ratio DESC LIMIT 10
WITH current_files AS (SELECT path FROM (SELECT old_path AS path, max(time) AS last_time, 2 AS change_type FROM git.clickhouse_file_changes GROUP BY old_path UNION ALL SELECT path, max(time) AS last_time, argMax(change_type, time) AS change_type FROM git.clickhouse_file_changes GROUP BY path) GROUP BY path HAVING (argMax(change_type, last_time) != 2) AND (NOT match(path, '(^dbms/)|(^libs/)|(^tests/testflows/)|(^programs/server/store/)')) ORDER BY path ASC), changes AS (SELECT path, max(time) AS max_time, commit_hash, any(lines_added) AS num_added, any(lines_deleted) AS num_deleted, any(change_type) AS type FROM git.clickhouse_file_changes WHERE (change_type IN ('Add', 'Modify')) AND (path IN (current_files)) AND (file_extension IN ('h', 'cpp', 'sql')) GROUP BY path, commit_hash ORDER BY path ASC, max_time ASC), rewrites AS (SELECT path, commit_hash, max_time, type, num_added, num_deleted, sum(num_added - num_deleted) OVER (PARTITION BY path ORDER BY max_time ASC) AS current_size, if(current_size > 0, num_added / current_size, 0) AS percent_add, if(current_size > 0, num_deleted / current_size, 0) AS percent_delete FROM changes) SELECT path, count() AS num_rewrites FROM rewrites WHERE (type = 'Modify') AND (percent_add >= 0.5) AND (percent_delete >= 0.5) AND (current_size > 50) GROUP BY path ORDER BY num_rewrites DESC LIMIT 10
SELECT day_of_week_added, count() AS num, avg(days_present) AS avg_days_present FROM (SELECT added_code.line, added_code.time AS added_day, dateDiff('day', added_code.time, removed_code.time) AS days_present FROM (SELECT path, line, max(time) AS time FROM git.clickhouse_line_changes WHERE (sign = 1) AND (line_type NOT IN ('Punct', 'Empty')) GROUP BY path, line) AS added_code INNER JOIN (SELECT path, line, max(time) AS time FROM git.clickhouse_line_changes WHERE (sign = -1) AND (line_type NOT IN ('Punct', 'Empty')) GROUP BY path, line) AS removed_code USING (path, line) WHERE removed_code.time > added_code.time) GROUP BY dayOfWeek(added_day) AS day_of_week_added
WITH current_files AS (SELECT path FROM (SELECT old_path AS path, max(time) AS last_time, 2 AS change_type FROM git.clickhouse_file_changes GROUP BY old_path UNION ALL SELECT path, max(time) AS last_time, argMax(change_type, time) AS change_type FROM git.clickhouse_file_changes GROUP BY path) GROUP BY path HAVING (argMax(change_type, last_time) != 2) AND (NOT match(path, '(^dbms/)|(^libs/)|(^tests/testflows/)|(^programs/server/store/)')) ORDER BY path ASC), lines_removed AS (SELECT added_code.path AS path, added_code.line, added_code.time AS added_day, dateDiff('day', added_code.time, removed_code.time) AS days_present FROM (SELECT path, line, max(time) AS time, any(file_extension) AS file_extension FROM git.clickhouse_line_changes WHERE (sign = 1) AND (line_type NOT IN ('Punct', 'Empty')) GROUP BY path, line) AS added_code INNER JOIN (SELECT path, line, max(time) AS time FROM git.clickhouse_line_changes WHERE (sign = -1) AND (line_type NOT IN ('Punct', 'Empty')) GROUP BY path, line) AS removed_code USING (path, line) WHERE (removed_code.time > added_code.time) AND (path IN (current_files)) AND (file_extension IN ('h', 'cpp', 'sql'))) SELECT path, avg(days_present) AS avg_code_age FROM lines_removed GROUP BY path ORDER BY avg_code_age DESC LIMIT 10
SELECT author, countIf((file_extension IN ('h', 'cpp', 'sql', 'sh', 'py', 'expect')) AND (path LIKE '%tests%')) AS test, countIf((file_extension IN ('h', 'cpp', 'sql')) AND (NOT (path LIKE '%tests%'))) AS code, code / (code + test) AS ratio_code FROM git.clickhouse_file_changes GROUP BY author HAVING code > 20 ORDER BY code DESC LIMIT 20
WITH (SELECT histogram(10)(ratio_code) AS hist FROM (SELECT author, countIf((file_extension IN ('h', 'cpp', 'sql', 'sh', 'py', 'expect')) AND (path LIKE '%tests%')) AS test, countIf((file_extension IN ('h', 'cpp', 'sql')) AND (NOT (path LIKE '%tests%'))) AS code, code / (code + test) AS ratio_code FROM git.clickhouse_file_changes GROUP BY author HAVING code > 20 ORDER BY code DESC LIMIT 20)) AS hist SELECT arrayJoin(hist).1 AS lower, arrayJoin(hist).2 AS upper, bar(arrayJoin(hist).3, 0, 100, 500) AS bar
SELECT author, avg(ratio_comments) AS avg_ratio_comments, sum(code) AS code FROM (SELECT author, commit_hash, countIf(line_type = 'Comment') AS comments, countIf(line_type = 'Code') AS code, if(comments > 0, comments / (comments + code), 0) AS ratio_comments FROM git.clickhouse_line_changes GROUP BY author, commit_hash) GROUP BY author ORDER BY code DESC LIMIT 10
WITH author_ratios_by_offset AS (SELECT author, dateDiff('week', start_dates.start_date, contributions.week) AS week_offset, ratio_code FROM (SELECT author, toStartOfWeek(min(time)) AS start_date FROM git.clickhouse_line_changes WHERE file_extension IN ('h', 'cpp', 'sql') GROUP BY author AS start_dates) AS start_dates INNER JOIN (SELECT author, countIf(line_type = 'Code') AS code, countIf((line_type = 'Comment') OR (line_type = 'Punct')) AS comments, comments / (comments + code) AS ratio_code, toStartOfWeek(time) AS week FROM git.clickhouse_line_changes WHERE (file_extension IN ('h', 'cpp', 'sql')) AND (sign = 1) GROUP BY time, author HAVING code > 20 ORDER BY author ASC, time ASC) AS contributions USING (author)) SELECT week_offset, avg(ratio_code) AS avg_code_ratio FROM author_ratios_by_offset GROUP BY week_offset HAVING (week_offset % 10) = 0 ORDER BY week_offset ASC LIMIT 20
WITH changes AS (SELECT path, commit_hash, max_time, type, num_added, num_deleted, sum(num_added - num_deleted) OVER (PARTITION BY path ORDER BY max_time ASC) AS current_size, if(current_size > 0, num_added / current_size, 0) AS percent_add, if(current_size > 0, num_deleted / current_size, 0) AS percent_delete FROM (SELECT path, max(time) AS max_time, commit_hash, any(file_lines_added) AS num_added, any(file_lines_deleted) AS num_deleted, any(file_change_type) AS type FROM git.clickhouse_line_changes WHERE (file_change_type IN ('Add', 'Modify')) AND (file_extension IN ('h', 'cpp', 'sql')) GROUP BY path, commit_hash ORDER BY path ASC, max_time ASC)), rewrites AS (SELECT any(max_time) OVER (PARTITION BY path ORDER BY max_time ASC ROWS BETWEEN 1 PRECEDING AND CURRENT ROW) AS previous_rewrite FROM changes WHERE (type = 'Modify') AND (percent_add >= 0.5) AND (percent_delete >= 0.5) AND (current_size > 50)) SELECT dayOfWeek(previous_rewrite) AS dayOfWeek, count() AS num_re_writes FROM rewrites GROUP BY dayOfWeek
WITH changes AS (SELECT path, author, commit_hash, max_time, type, num_added, num_deleted, sum(num_added - num_deleted) OVER (PARTITION BY path ORDER BY max_time ASC) AS current_size, if(current_size > 0, num_added / current_size, 0) AS percent_add, if(current_size > 0, num_deleted / current_size, 0) AS percent_delete FROM (SELECT path, any(author) AS author, max(time) AS max_time, commit_hash, any(file_lines_added) AS num_added, any(file_lines_deleted) AS num_deleted, any(file_change_type) AS type FROM git.clickhouse_line_changes WHERE (file_change_type IN ('Add', 'Modify')) AND (file_extension IN ('h', 'cpp', 'sql')) GROUP BY path, commit_hash ORDER BY path ASC, max_time ASC)), rewrites AS (SELECT *, any(max_time) OVER (PARTITION BY path ORDER BY max_time ASC ROWS BETWEEN 1 PRECEDING AND CURRENT ROW) AS previous_rewrite, dateDiff('day', previous_rewrite, max_time) AS rewrite_days, any(author) OVER (PARTITION BY path ORDER BY max_time ASC ROWS BETWEEN 1 PRECEDING AND CURRENT ROW) AS prev_author FROM changes WHERE (type = 'Modify') AND (percent_add >= 0.5) AND (percent_delete >= 0.5) AND (current_size > 50)) SELECT prev_author, avg(rewrite_days) AS c, uniq(path) AS num_files FROM rewrites GROUP BY prev_author HAVING num_files > 2 ORDER BY c DESC LIMIT 10
WITH commit_days AS (SELECT author, day, any(day) OVER (PARTITION BY author ORDER BY day ASC ROWS BETWEEN 1 PRECEDING AND CURRENT ROW) AS previous_commit, dateDiff('day', previous_commit, day) AS days_since_last, if(days_since_last = 1, 1, 0) AS consecutive_day FROM (SELECT author, toStartOfDay(time) AS day FROM git.clickhouse_commits GROUP BY author, day ORDER BY author ASC, day ASC)) SELECT author, arrayMax(arrayMap(x -> length(x), arraySplit(x -> (x = 0), groupArray(consecutive_day)))) AS max_consecutive_days FROM commit_days GROUP BY author ORDER BY max_consecutive_days DESC LIMIT 10
SELECT time, path, old_path, commit_hash, commit_message FROM git.clickhouse_file_changes WHERE (path = 'src/Storages/StorageReplicatedMergeTree.cpp') AND (change_type = 'Rename')
SELECT round(toUInt32OrZero(extract(menu_date, '^\\d{4}')), -1) AS d, count(), round(avg(price), 2), bar(avg(price), 0, 50, 100), any(dish_name) FROM food.menu_item_denorm WHERE (menu_currency IN ('Dollars', '')) AND (d > 0) AND (d < 2022) AND (dish_name ILIKE '%caviar%') GROUP BY d ORDER BY d ASC
SELECT * FROM uk.uk_price_paid LIMIT 10
SELECT town, district, count() AS c, round(avg(price)) AS price, bar(price, 0, 5000000, 100) FROM uk.uk_price_paid WHERE date >= '2020-01-01' GROUP BY town, district HAVING c >= 100 ORDER BY price DESC LIMIT 100
SELECT town, avg(price) AS avg_price FROM uk.uk_price_paid GROUP BY town
SELECT toYear(date) AS year, round(avg(price)) AS price FROM uk.uk_price_paid WHERE type = 'flat' GROUP BY year ORDER BY year ASC
SELECT postcode1, round(avg(price)) AS price FROM uk.uk_price_paid WHERE (town = 'BRISTOL') AND (postcode1 != '') GROUP BY postcode1 ORDER BY price DESC LIMIT 10
SELECT postcode1, medianIf(price, toYear(date) = 2002) AS median_2002, medianIf(price, toYear(date) = 2022) AS median_2022, round(((median_2022 - median_2002) / median_2002) * 100) AS percent_change FROM uk.uk_price_paid WHERE town = 'LONDON' GROUP BY postcode1 ORDER BY percent_change DESC
SELECT postcode1, medianIf(price, toYear(date) = 2002) AS median_2002, medianIf(price, toYear(date) = 2021) AS median_2021, round(((median_2021 - median_2002) / median_2002) * 100) AS percent_change FROM uk.uk_price_paid WHERE town = 'LONDON' GROUP BY postcode1 ORDER BY percent_change ASC
SHOW CREATE TABLE uk.uk_price_paid
SELECT county, price FROM uk.uk_price_paid WHERE town = 'LONDON' ORDER BY price DESC LIMIT 3
SELECT county, price FROM uk.uk_price_paid_oby_town_price WHERE town = 'LONDON' ORDER BY price DESC LIMIT 3
EXPLAIN actions = 1 SELECT county, price FROM uk.uk_price_paid_oby_town_price WHERE town = 'LONDON' ORDER BY price DESC LIMIT 3
EXPLAIN PIPELINE SELECT county, price FROM uk.uk_price_paid WHERE town = 'LONDON' ORDER BY price DESC LIMIT 3
SELECT county, avg(price) FROM uk.uk_price_paid GROUP BY county ORDER BY avg(price) DESC LIMIT 3
SELECT * FROM uk.uk_price_paid LIMIT 1
SELECT postcode1, postcode2, formatReadableQuantity(avg(price)) AS avg_price FROM uk.uk_price_paid GROUP BY postcode1, postcode2 LIMIT 1
SELECT month, countIf(duration = 'leasehold') AS `Leasehold Sold`, countIf(duration = 'freehold') AS `Freehold Sold`, avgIf(price, duration = 'freehold') AS `Average Freehold Price`, avgIf(price, duration = 'leasehold') AS `Average Leasehold Price` FROM uk.uk_price_paid GROUP BY toStartOfMonth(date) AS month ORDER BY month ASC
SELECT code, (anyIf(med_2020, med_2020 > 0) - anyIf(med_2000, med_2000 > 0)) / anyIf(med_2000, med_2000 > 0) AS percent_change FROM (SELECT code, medianIf(price, year = 2000) AS med_2000, medianIf(price, year = 2020) AS med_2020 FROM (SELECT date, price, locality, town, district, county, code FROM uk.uk_price_paid LEFT JOIN uk.uk_codes AS codes ON (uk.uk_price_paid.county = codes.name) OR (uk.uk_price_paid.district = codes.name) OR (uk.uk_price_paid.town = codes.name) OR (uk.uk_price_paid.locality = codes.name) OR (replaceAll(uk.uk_price_paid.district, 'CITY OF ', '') = codes.name)) WHERE (code != '') AND ((toYear(date) = 2000) OR (toYear(date) = 2020)) GROUP BY code, toYear(date) AS year ORDER BY code ASC) GROUP BY code ORDER BY percent_change DESC
SELECT DayOfWeek, count(*) AS c FROM ontime.ontime WHERE (Year >= 2000) AND (Year <= 2008) GROUP BY DayOfWeek ORDER BY c DESC
SELECT origin, count(), round(avg(geoDistance(longitude_1, latitude_1, longitude_2, latitude_2))) AS distance, bar(distance, 0, 10000000, 100) AS bar FROM opensky.opensky WHERE origin != '' GROUP BY origin ORDER BY count() DESC LIMIT 100
SELECT toStartOfYear(date) AS time, town, round(avg(price)) AS price FROM uk.uk_price_paid WHERE town IN (SELECT town FROM uk.uk_price_paid WHERE town != 'GATWICK' GROUP BY town ORDER BY avg(price) DESC LIMIT 10) GROUP BY time, town ORDER BY time ASC
SELECT toStartOfYear(date) AS time, district, round(avg(price)) AS price FROM uk.uk_price_paid WHERE (district IN (SELECT district FROM uk.uk_price_paid WHERE town = 'LONDON' GROUP BY district ORDER BY avg(price) DESC LIMIT 10)) AND (district IN ('TOWER HAMLETS', 'HACKNEY', 'NEWHAM', 'CITY OF LONDON', 'WALTHAM FOREST', 'REDBRIDGE', 'BARKING AND DAGENHAM', 'HAVERING', 'HARINGEY', 'EPPING FOREST', 'ISLINGTON', 'CAMDEN', 'CITY OF WESTMINSTER', 'BARNET', 'HARROW', 'HILLINGDON', 'ENFIELD', 'EALING', 'HOUNSLOW', 'HAMMERSMITH AND FULHAM', 'LEWISHAM', 'BRENT', 'WANDSWORTH', 'SOUTHWARK', 'LAMBETH', 'GREENWICH', 'KENSINGTON AND CHELSEA', 'MERTON', 'BROMLEY', 'RICHMOND UPON THAMES', 'CROYDON', 'BEXLEY', 'KINGSTON UPON THAMES', 'HARLOW', 'SUTTON', 'CITY OF BRISTOL', 'MALVERN HILLS', 'THURROCK', 'RHONDDA CYNON TAFF')) GROUP BY time, district ORDER BY time ASC
SELECT toStartOfYear(date) AS time, district, round(avg(price)) AS price FROM uk.uk_price_paid WHERE (district IN (SELECT district FROM uk.uk_price_paid WHERE uk.uk_price_paid.town = 'LONDON' GROUP BY district ORDER BY avg(price) DESC LIMIT 10)) AND (1 = 1) GROUP BY time, district ORDER BY time ASC
SELECT count() FROM noaa.noaa
SELECT tempMax / 10 AS maxTemp, station_id, date, location FROM noaa.noaa WHERE substring(station_id, 1, 2) = 'PO' ORDER BY tempMax DESC LIMIT 5
SELECT tempMax / 10 AS maxTemp, station_id, date, location, name FROM noaa.noaa WHERE station_id IN (SELECT station_id FROM noaa.stations WHERE country_code = 'PO') ORDER BY tempMax DESC LIMIT 5
SELECT tempMax / 10 AS maxTemp, station_id, date, stations.name AS name, (stations.lat, stations.lon) AS location FROM noaa.noaa INNER JOIN noaa.stations ON noaa.station_id = stations.station_id WHERE stations.country_code = 'PO' ORDER BY tempMax DESC LIMIT 5
SELECT dictGet(noaa.stations_dict, 'state', 'CA00116HFF6')
SELECT tempMax / 10 AS maxTemp, station_id, date, (dictGet('noaa.stations_dict', 'lat', station_id), dictGet('noaa.stations_dict', 'lon', station_id)) AS location, dictGet('noaa.stations_dict', 'name', station_id) AS name FROM noaa.noaa WHERE station_id IN (SELECT station_id FROM noaa.stations WHERE country_code = 'PO') ORDER BY tempMax DESC LIMIT 5
SELECT tempMax / 10 AS maxTemp, station_id, date, (dictGet('noaa.stations_dict', 'lat', station_id), dictGet('noaa.stations_dict', 'lon', station_id)) AS location, dictGet('noaa.stations_dict', 'name', station_id) AS name FROM noaa.noaa WHERE dictGet('noaa.stations_dict', 'country_code', station_id) = 'PO' ORDER BY tempMax DESC LIMIT 5
SELECT week, toYear(week) AS year, lat, lon, avg_precipitation, max_wind_speed * 10 FROM (SELECT geoHash, week, geohashDecode(geoHash) AS lonlat, lonlat.1 AS lon, lonlat.2 AS lat, max(maxWindSpeed) AS max_wind_speed, avg(precipitation) / 10 AS avg_precipitation FROM noaa.noaa WHERE (dictGet(country.country_polygons, 'name', location) IN ('United States of America')) AND (elevation < 500) AND ((toMonth(date) >= 6) AND (toMonth(date) <= 10)) GROUP BY geohashEncode(location.1, location.2, 4) AS geoHash, toStartOfWeek(date) AS week HAVING (max_wind_speed > 300) AND (avg_precipitation > 20) ORDER BY max_wind_speed DESC) ORDER BY year ASC, max_wind_speed DESC LIMIT 2 BY year
SELECT * FROM noaa.states LIMIT 2
SELECT resort_name, total_snow / 1000 AS total_snow_m, resort_location, month_year FROM (SELECT resort_name, highest_snow.station_id, geoDistance(lon, lat, station_location.1, station_location.2) / 1000 AS distance_km, highest_snow.total_snow, station_location, month_year, (lon, lat) AS resort_location FROM (SELECT sum(snowfall) AS total_snow, station_id, any(location) AS station_location, month_year, substring(station_id, 1, 2) AS code FROM noaa.noaa WHERE (date > '2017-01-01') AND (code = 'US') AND (elevation > 1800) GROUP BY station_id, toYYYYMM(date) AS month_year ORDER BY total_snow DESC LIMIT 1000) AS highest_snow INNER JOIN noaa.resorts ON highest_snow.code = resorts.code WHERE distance_km < 20 ORDER BY resort_name ASC, total_snow DESC LIMIT 1 BY resort_name, station_id) ORDER BY total_snow DESC LIMIT 5
SELECT resort_name, total_snow / 1000 AS total_snow_m, resort_location, month_year FROM (SELECT resort_name, highest_snow.station_id, geoDistance(resorts_dict.lon, resorts_dict.lat, station_lon, station_lat) / 1000 AS distance_km, highest_snow.total_snow, (resorts_dict.lon, resorts_dict.lat) AS resort_location, month_year FROM (SELECT sum(snowfall) AS total_snow, station_id, dictGet('noaa.stations_dict', 'lat', station_id) AS station_lat, dictGet('noaa.stations_dict', 'lon', station_id) AS station_lon, month_year, dictGet('noaa.stations_dict', 'state', station_id) AS state FROM noaa.noaa WHERE (date > '2017-01-01') AND (state != '') AND (elevation > 1800) GROUP BY station_id, toYYYYMM(date) AS month_year ORDER BY total_snow DESC LIMIT 1000) AS highest_snow INNER JOIN noaa.resorts_dict ON highest_snow.state = resorts_dict.state WHERE distance_km < 20 ORDER BY resort_name ASC, total_snow DESC LIMIT 1 BY resort_name, station_id) ORDER BY total_snow DESC LIMIT 5
SELECT code, min(tempMin) / 10 AS min_temp FROM noaa.noaa WHERE date > '1970-01-01' GROUP BY substring(station_id, 1, 2) AS code LIMIT 1000
SELECT geoHash, month, avg(percentDailySun) AS avg_daily_sun, geohashDecode(geoHash) AS lonlat, lonlat.1 AS lon, lonlat.2 AS lat, avg(tempAvg) / 10 AS avg_temp, max(tempMax) / 10 AS max_temp, min(tempMin) / 10 AS min_temp, sum(precipitation) AS sum_precipitation, avg(elevation) AS avg_elevation FROM noaa.noaa WHERE date > '1970-01-01' GROUP BY geohashEncode(location.1, location.2, 4) AS geoHash, toMonth(date) AS month HAVING (max_temp < 40) AND (min_temp > 0) AND (avg_temp > 10) AND (sum_precipitation < 100) AND (avg_elevation < 1000)
SELECT values.1 AS labels, values.2 AS count FROM (SELECT arrayJoin([('not_too_cold', countIf(min_temp > 0)), ('not_too_cold_or_cold', countIf((min_temp > 0) AND (max_temp < 40))), ('ideal_temp', countIf((max_temp < 40) AND (min_temp > 0) AND (avg_temp > 10))), ('ideal_temp_min_rain', countIf((max_temp < 40) AND (min_temp > 0) AND (avg_temp > 10) AND (sum_precipitation < 100))), ('ideal_temp_min_rain_not_high', countIf((max_temp < 40) AND (min_temp > 0) AND (avg_temp > 10) AND (sum_precipitation < 100) AND (avg_elevation < 1000)))]) AS values FROM (SELECT geoHash, month, avg(percentDailySun) AS avg_daily_sun, geohashDecode(geoHash) AS lonlat, lonlat.1 AS lat, lonlat.2 AS lon, avg(tempAvg) / 10 AS avg_temp, max(tempMax) / 10 AS max_temp, min(tempMin) / 10 AS min_temp, sum(precipitation) AS sum_precipitation, avg(elevation) AS avg_elevation FROM noaa.noaa WHERE date > '1970-01-01' GROUP BY geohashEncode(location.1, location.2, 4) AS geoHash, toMonth(date) AS month))
SELECT name, formatReadableSize(sum(data_compressed_bytes)) AS compressed_size, formatReadableSize(sum(data_uncompressed_bytes)) AS uncompressed_size, round(sum(data_uncompressed_bytes) / sum(data_compressed_bytes), 2) AS ratio FROM system.columns WHERE `table` = 'noaa_codec_v1' GROUP BY name ORDER BY sum(data_compressed_bytes) DESC
SELECT name, formatReadableSize(sum(data_compressed_bytes)) AS compressed_size, formatReadableSize(sum(data_uncompressed_bytes)) AS uncompressed_size, round(sum(data_uncompressed_bytes) / sum(data_compressed_bytes), 2) AS ratio FROM system.columns WHERE `table` = 'noaa_codec_v2' GROUP BY name ORDER BY sum(data_compressed_bytes) DESC
SELECT name, formatReadableSize(sum(data_compressed_bytes)) AS compressed_size, formatReadableSize(sum(data_uncompressed_bytes)) AS uncompressed_size, round(sum(data_uncompressed_bytes) / sum(data_compressed_bytes), 2) AS ratio FROM system.columns WHERE `table` = 'noaa_codec_v3' GROUP BY name ORDER BY sum(data_compressed_bytes) DESC
SELECT name, formatReadableSize(sum(data_compressed_bytes)) AS compressed_size, formatReadableSize(sum(data_uncompressed_bytes)) AS uncompressed_size, round(sum(data_uncompressed_bytes) / sum(data_compressed_bytes), 2) AS ratio FROM system.columns WHERE `table` = 'noaa_codec_v4' GROUP BY name ORDER BY sum(data_compressed_bytes) DESC
SELECT name, formatReadableSize(sum(data_compressed_bytes)) AS compressed_size, formatReadableSize(sum(data_uncompressed_bytes)) AS uncompressed_size, round(sum(data_uncompressed_bytes) / sum(data_compressed_bytes), 2) AS ratio FROM system.columns WHERE `table` = 'noaa_codec_optimal' GROUP BY name ORDER BY sum(data_compressed_bytes) DESC
SELECT name, if(argMin(compression_codec, data_compressed_bytes) != '', argMin(compression_codec, data_compressed_bytes), 'DEFAULT') AS best_codec, formatReadableSize(min(data_compressed_bytes)) AS compressed_size FROM system.columns WHERE `table` LIKE 'noaa_codec%' GROUP BY name
SELECT formatReadableSize(sum(data_compressed_bytes)) AS compressed_size, formatReadableSize(sum(data_uncompressed_bytes)) AS uncompressed_size, round(sum(data_uncompressed_bytes) / sum(data_compressed_bytes), 2) AS ratio FROM system.columns WHERE `table` = 'noaa_codec_v1'
SELECT formatReadableSize(sum(data_compressed_bytes)) AS compressed_size, formatReadableSize(sum(data_uncompressed_bytes)) AS uncompressed_size, round(sum(data_uncompressed_bytes) / sum(data_compressed_bytes), 2) AS ratio FROM system.columns WHERE `table` = 'noaa_codec_v2'
SELECT formatReadableSize(sum(data_compressed_bytes)) AS compressed_size, formatReadableSize(sum(data_uncompressed_bytes)) AS uncompressed_size, round(sum(data_uncompressed_bytes) / sum(data_compressed_bytes), 2) AS ratio FROM system.columns WHERE `table` = 'noaa_codec_v3'
SELECT formatReadableSize(sum(data_compressed_bytes)) AS compressed_size, formatReadableSize(sum(data_uncompressed_bytes)) AS uncompressed_size, sum(data_uncompressed_bytes) / sum(data_compressed_bytes) AS compression_ratio FROM system.columns WHERE `table` = 'noaa_codec_v4'
SELECT formatReadableSize(sum(data_compressed_bytes)) AS compressed_size, formatReadableSize(sum(data_uncompressed_bytes)) AS uncompressed_size, round(sum(data_uncompressed_bytes) / sum(data_compressed_bytes), 2) AS ratio FROM system.columns WHERE `table` = 'noaa_codec_optimal'
SELECT elevation_range, uniq(station_id) AS num_stations, max(tempMax) / 10 AS max_temp, min(tempMin) / 10 AS min_temp, sum(precipitation) AS total_precipitation, avg(percentDailySun) AS avg_percent_sunshine, max(maxWindSpeed) AS max_wind_speed, sum(snowfall) AS total_snowfall FROM noaa.noaa_codec_v1 WHERE (date > '1970-01-01') AND (station_id IN (SELECT station_id FROM noaa.stations WHERE country_code = 'US')) GROUP BY floor(elevation, -2) AS elevation_range ORDER BY elevation_range ASC
SELECT COLUMNS('Wind|temp|snow|pre') APPLY min, COLUMNS('Wind|temp|snow|pre') APPLY max FROM noaa.noaa
SELECT year, avg(precipitation) AS avg_precipitation, dictGet(country.country_iso_codes, 'name', code) AS country FROM noaa.noaa_v2 WHERE (date > '1970-01-01') AND (code IN ('AL', 'AN', 'AU', 'BE', 'BO', 'CY', 'DA', 'EI', 'EZ', 'EN', 'FI', 'FR', 'GG', 'GI', 'GK', 'GM', 'GR', 'HR', 'HU', 'IC', 'IM', 'IT', 'JE', 'LG', 'LH', 'LO', 'LS', 'LU', 'MD', 'MK', 'MN', 'MT', 'NL', 'NO', 'PL', 'PO', 'RO', 'SI', 'SM', 'SP', 'SW', 'SZ', 'TU', 'UK', 'UP', 'VT')) GROUP BY toStartOfYear(date) AS year, substring(station_id, 1, 2) AS code HAVING avg_precipitation > 0 ORDER BY country ASC, year ASC LIMIT 100000
SHOW TABLES FROM noaa WHERE name = 'noaa'
SELECT countIf(precipitation = 0) AS num_empty, countIf(precipitation > 0) AS num_non_zero, num_empty / (num_empty + num_non_zero) AS ratio FROM noaa.noaa
SELECT elevation_range, uniq(station_id) AS num_stations, max(tempMax) / 10 AS max_temp, min(tempMin) / 10 AS min_temp, sum(precipitation) AS total_precipitation, avg(percentDailySun) AS avg_percent_sunshine, max(maxWindSpeed) AS max_wind_speed, sum(snowfall) AS total_snowfall FROM noaa.noaa_codec_v3 WHERE (date > '1970-01-01') AND (station_id IN (SELECT station_id FROM noaa.stations WHERE country_code = 'US')) GROUP BY floor(elevation, -2) AS elevation_range ORDER BY elevation_range ASC
SELECT elevation_range, uniq(station_id) AS num_stations, max(tempMax) / 10 AS max_temp, min(tempMin) / 10 AS min_temp, sum(precipitation) AS total_precipitation, avg(percentDailySun) AS avg_percent_sunshine, max(maxWindSpeed) AS max_wind_speed, sum(snowfall) AS total_snowfall FROM noaa.noaa_codec_optimal WHERE (date > '1970-01-01') AND (station_id IN (SELECT station_id FROM noaa.stations WHERE country_code = 'US')) GROUP BY floor(elevation, -2) AS elevation_range ORDER BY elevation_range ASC
SELECT tempMax / 10 AS maxTemp, location, name, date FROM noaa.noaa ORDER BY tempMax DESC, date ASC LIMIT 5
SELECT tempMax / 10 AS maxTemp, station_id, date, location FROM noaa.noaa WHERE dictGet(country.country_polygons, 'name', location) = 'Portugal' ORDER BY tempMax DESC LIMIT 5
SELECT tempMax / 10 AS maxTemp, station_id, date, location FROM noaa.noaa WHERE dictGet(country.country_polygons, 'name', location) = 'Canada' ORDER BY tempMax DESC LIMIT 5
SELECT tempMax / 10 AS maxTemp, station_id, date, location FROM noaa.noaa WHERE substring(station_id, 1, 2) = 'CA' ORDER BY tempMax DESC LIMIT 5
SELECT geoHash, geohashDecode(geoHash) AS lon_lat, max(tempMax) / 10 AS max_temp FROM noaa.noaa WHERE (date > '1970-01-01') AND (dictGet(country.country_polygons, 'name', location) IN ('United States of America', 'Mexico')) GROUP BY geohashEncode(location.1, location.2, 3) AS geoHash
SELECT `table`, formatReadableSize(sum(data_compressed_bytes)) AS compressed_size, formatReadableSize(sum(data_uncompressed_bytes)) AS uncompressed_size, sum(data_compressed_bytes) / sum(data_uncompressed_bytes) AS compression_ratio FROM system.columns WHERE (database = 'forex') AND (`table` = 'forex') GROUP BY `table` ORDER BY `table` ASC
SELECT base, quote, day, close, close - any(close) OVER (PARTITION BY base, quote ORDER BY base ASC, quote ASC, day ASC ROWS BETWEEN 1 PRECEDING AND CURRENT ROW) AS change FROM (SELECT base, quote, day, argMax(ask, datetime) AS close FROM forex.forex WHERE (quote = 'GBP') AND (base = 'EUR') AND (datetime > '2016-01-01 00:00:00.000') AND (datetime < '2017-01-01 00:00:00.000') GROUP BY base, quote, toStartOfDay(datetime) AS day ORDER BY base ASC, quote ASC, day ASC) ORDER BY base ASC, quote ASC, day ASC
SELECT base, quote, min(datetime) FROM forex.forex_usd GROUP BY base, quote
SELECT base, quote, day, spread - any(spread) OVER (PARTITION BY base, quote ORDER BY base ASC, quote ASC, day ASC ROWS BETWEEN 1 PRECEDING AND CURRENT ROW) AS change FROM (SELECT base, quote, avg(ask - bid) AS spread, day FROM forex.forex WHERE (base = 'EUR') AND (quote = 'USD') GROUP BY base, quote, toYYYYMMDD(datetime) AS day ORDER BY base ASC, quote ASC, day ASC) ORDER BY change DESC LIMIT 5
WITH daily_change AS (SELECT base, quote, day, close, close - any(close) OVER (PARTITION BY base, quote ORDER BY base ASC, quote ASC, day ASC ROWS BETWEEN 1 PRECEDING AND CURRENT ROW) AS change FROM (SELECT base, quote, day, argMax(ask, datetime) AS close FROM forex.forex WHERE (quote = 'GBP') OR (base = 'GBP') GROUP BY base, quote, toStartOfDay(datetime) AS day ORDER BY base ASC, quote ASC, day ASC) ORDER BY base ASC, quote ASC, day ASC) SELECT * FROM daily_change WHERE day > '2016-01-02 00:00:00' ORDER BY abs(change) DESC LIMIT 1 BY base, quote
SELECT day, argMax(ask, datetime) AS price FROM forex.forex WHERE (datetime > '2010-01-01 00:00:00') AND (base = 'BCO') AND (quote = 'USD') GROUP BY toStartOfDay(datetime) AS day ORDER BY day ASC
SELECT day, stddevPop(change) OVER (PARTITION BY base, quote ORDER BY day ASC ROWS BETWEEN 30 PRECEDING AND CURRENT ROW) AS volatility, if(abs(change) > volatility, 'true', 'false') AS volitile FROM (SELECT base, quote, day, close, close - any(close) OVER (PARTITION BY base, quote ORDER BY base ASC, quote ASC, day ASC ROWS BETWEEN 1 PRECEDING AND CURRENT ROW) AS change FROM (SELECT base, quote, day, argMax(ask, datetime) AS close FROM forex.forex WHERE (quote = 'USD') AND (base = 'GBP') AND (datetime > '2010-01-01 00:00:00') GROUP BY base, quote, toStartOfDay(datetime) AS day ORDER BY base ASC, quote ASC, day ASC) ORDER BY base ASC, quote ASC, day ASC) ORDER BY base ASC, quote ASC, day ASC
SELECT toStartOfDay(datetime) AS time, quote, argMax(bid, datetime) AS close FROM forex.forex WHERE (base = 'EUR') AND (quote IN ('GBP', 'USD', 'NZD', 'CND')) AND (datetime >= '1464739200') AND (datetime <= '1633046400') GROUP BY time, quote ORDER BY time ASC, quote ASC
SELECT toStartOfDay(datetime) AS day, argMin(ask, datetime) AS open, argMax(ask, datetime) AS close, max(ask) AS high, min(ask) AS low FROM forex.forex WHERE (base = 'EUR') AND (quote = 'USD') AND (datetime >= '1464739200') AND (datetime <= '1633046400') GROUP BY day ORDER BY day ASC
SELECT toYYYYMM(toDateTime(time)) AS monthYear, bar(count(), 0, 120, 20) AS count FROM hackernews.hackernews WHERE text ILIKE '%ClickHouse%' GROUP BY monthYear ORDER BY monthYear ASC
SELECT count() AS `posts per month`, toStartOfMonth(time) AS month FROM hackernews.hackernews WHERE (type IN ('comment', 'story')) AND ((text ILIKE '%ClickHouse%') OR (title ILIKE '%ClickHouse%')) GROUP BY month ORDER BY month ASC LIMIT 1000
WITH stop_words AS (SELECT token FROM words.stop_words) SELECT phrase, count() AS c FROM (SELECT arrayJoin(shingles) AS shingle, concat(shingle.1, ' ', shingle.2) AS phrase FROM (SELECT tokens, arrayFilter(t -> (NOT ((t.2) IS NULL)), arrayZip(tokens, arrayPushBack(arrayPopFront(tokens), NULL))) AS shingles FROM (SELECT arrayFilter(t -> ((t NOT IN (stop_words)) AND (length(t) > 2)), alphaTokens(title)) AS tokens FROM hackernews.hackernews WHERE type IN ('story', 'comment')) WHERE length(tokens) > 0)) GROUP BY phrase ORDER BY c DESC LIMIT 20
SELECT now() - (toDateTime('1998-05-08 13:44:46') - timestamp) AS log_time, multiIf(message.status > 500, 'critical', message.status > 400, 'error', message.status > 300, 'warning', 'info') AS level, message.request.method AS method, message.status AS status, message.size AS size, message.request AS log FROM logs.http_logs ORDER BY timestamp DESC LIMIT 10000
SELECT * FROM logs.http_logs LIMIT 10
SELECT number, parity_str(number) FROM numbers(5)
SELECT randCanonical()
SELECT randUniform(5, 10)
SELECT floor(randUniform(5, 10)) AS r
SELECT randNormal(100, 5)
SELECT floor(randNormal(100, 5)) AS k, count(*) AS c, bar(c, 0, 50000, 100) FROM numbers(100000) GROUP BY k ORDER BY k ASC
SELECT floor(randBinomial(100, 0.85)) AS k, bar(count(*), 0, 50000, 100) AS b1 FROM numbers(100000) GROUP BY k ORDER BY k ASC
SELECT floor(randNegativeBinomial(100, 0.85)) AS k, bar(count(*), 0, 50000, 100) AS b1 FROM numbers(100000) GROUP BY k ORDER BY k ASC
SELECT floor(randLogNormal(1 / 100, 0.75)) AS k, bar(count(*), 0, 50000, 10) AS b1 FROM numbers(100000) GROUP BY k ORDER BY k ASC
SELECT floor(randExponential(1 / 2)) AS k, bar(count(*), 0, 50000, 10) AS b1 FROM numbers(100000) GROUP BY k ORDER BY k ASC
SELECT floor(randChiSquared(10)) AS k, bar(count(*), 0, 10000, 10) AS b1 FROM numbers(100000) GROUP BY k ORDER BY k ASC
SELECT floor(randStudentT(4.5)) AS k, bar(count(*), 0, 10000, 10) AS b1 FROM numbers(100000) GROUP BY k ORDER BY k ASC
SELECT floor(randFisherF(3, 20)) AS k, bar(count(*), 0, 10000, 10) AS b1 FROM numbers(100000) GROUP BY k ORDER BY k ASC
SELECT floor(randPoisson(10)) AS k, bar(count(*), 0, 15000, 10) AS b1 FROM numbers(100000) GROUP BY k ORDER BY k ASC
SELECT floor(randBernoulli(0.75)) AS k, count(*) FROM numbers(100000) GROUP BY k ORDER BY k ASC
SELECT floor(total_spent) AS s, count(*) AS n, bar(n, 0, 350000, 50) FROM random.purchases GROUP BY s ORDER BY s ASC
SELECT toStartOfHour(dt) AS hour, count(*) AS c, bar(c, 0, 15000, 50) FROM random.events GROUP BY hour ORDER BY hour ASC
SELECT toStartOfHour(dt) AS h, round(avg(val), 2) AS v, bar(v, 0, 100) FROM random.metrics GROUP BY h ORDER BY h ASC
SELECT randBernoulli(0.9)
SELECT If(randBernoulli(0.95), 'success', 'failure') AS status, count(*) AS c FROM numbers(1000) GROUP BY status
SELECT ['200', '404', '502', '403'][toInt32(randBinomial(4, 0.1)) + 1] AS http_code, count(*) FROM numbers(1000) GROUP BY http_code
SELECT randomPrintableASCII(randUniform(5, 25)) AS s, length(s) AS length FROM numbers(10)
SELECT fuzzBits('Good string', 0.01) FROM numbers(10)
SELECT IF(fuzzBits('Good string', 0.001) = 'Good string', 1, 0) AS has_errors, count(*) FROM numbers(1000) GROUP BY has_errors
SELECT dt, count(*) AS c, bar(c, 0, 100000) FROM random.click_events GROUP BY dt ORDER BY dt ASC
SHOW CREATE TABLE metrica.hits
SELECT sum(hits) AS h, toDate(time) AS d FROM wiki.wikistat_small GROUP BY d ORDER BY d ASC LIMIT 5
SELECT sum(hits) AS v, toStartOfHour(time) AS h FROM wiki.wikistat_small WHERE date(time) = '2015-05-01' GROUP BY h ORDER BY h ASC LIMIT 5
SELECT sum(hits) AS v, toStartOfInterval(time, toIntervalHour(4)) AS h FROM wiki.wikistat_small WHERE date(time) = '2015-05-01' GROUP BY h ORDER BY h ASC LIMIT 6
SELECT toStartOfHour(time) AS h, sum(hits) FROM wiki.wikistat_small WHERE (project = 'it') AND (subproject = 'm') AND (date(time) = '2015-06-12') GROUP BY h ORDER BY h ASC
SELECT toStartOfHour(time) AS h, sum(hits) FROM wiki.wikistat_small WHERE (project = 'it') AND (subproject = 'm') AND (date(time) = '2015-06-12') GROUP BY h ORDER BY h ASC WITH FILL STEP toIntervalHour(1)
SELECT sum(hits), dateDiff('day', toDateTime('2015-05-01 18:00:00'), toDateTime(time)) AS d FROM wiki.wikistat_small GROUP BY d ORDER BY d ASC LIMIT 5
SELECT toHour(time) AS h, sum(hits) AS t, bar(t, 0, max(t) OVER ()) FROM wiki.wikistat_small GROUP BY h ORDER BY h ASC
WITH histogram(10)(hits) AS h SELECT round(arrayJoin(h).1) AS l, round(arrayJoin(h).2) AS u, arrayJoin(h).3 AS w, bar(w, 0, max(w) OVER (), 20) AS b FROM (SELECT path, sum(hits) AS hits FROM wiki.wikistat_small WHERE date(time) = '2015-06-15' GROUP BY path HAVING hits > 10000.)
SELECT toDate(time) AS d, sum(hits) AS h, lagInFrame(h) OVER (ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS p, h - p AS trend FROM wiki.wikistat_small WHERE path = 'Bob' GROUP BY d ORDER BY d ASC LIMIT 15
SELECT toDate(time) AS d, sum(hits) AS h, sum(h) OVER (ROWS BETWEEN UNBOUNDED PRECEDING AND 0 FOLLOWING) AS c, bar(c, 0, 3200000, 25) AS b FROM wiki.wikistat_small WHERE path = 'Bob' GROUP BY d ORDER BY d ASC LIMIT 15
SELECT toStartOfHour(time) AS t, sum(hits) AS h, round(h / (60 * 60), 2) AS rate, bar(rate * 10, 0, max(rate * 10) OVER (), 25) AS b FROM wiki.wikistat_small WHERE path = 'Bob' GROUP BY t ORDER BY t ASC LIMIT 23
SELECT uniq(project), uniq(subproject) FROM wiki.wikistat_small
SELECT max(hits) FROM wiki.wikistat_small
SELECT project, sum(hits) AS h FROM wiki.wikistat_small GROUP BY project ORDER BY h DESC LIMIT 10
SELECT project, sum(hits) AS h FROM wiki.optimized_wikistat_small GROUP BY project ORDER BY h DESC LIMIT 10
SELECT subproject, sum(hits) AS h FROM wiki.wikistat_small WHERE project = 'it' GROUP BY subproject ORDER BY h DESC LIMIT 10
SELECT subproject, sum(hits) AS h FROM wiki.optimized_wikistat_small WHERE project = 'it' GROUP BY subproject ORDER BY h DESC LIMIT 10
SELECT toStartOfMonth(time) AS m, sum(hits) AS h FROM wiki.wikistat_small WHERE (project = 'it') AND (subproject = 'zero') GROUP BY m ORDER BY m DESC LIMIT 10
SELECT toStartOfMonth(time) AS m, sum(hits) AS h FROM wiki.optimized_wikistat_small WHERE (project = 'it') AND (subproject = 'zero') GROUP BY m ORDER BY m DESC LIMIT 10
SELECT path, sum(hits) AS h FROM wiki.wikistat_small WHERE (project = 'it') AND (subproject = 'zero') GROUP BY path ORDER BY h DESC LIMIT 10
SELECT path, sum(hits) AS h FROM wiki.optimized_wikistat_small WHERE (project = 'it') AND (subproject = 'zero') GROUP BY path ORDER BY h DESC LIMIT 10
SELECT path, hits FROM wiki.wikistat_top WHERE month = '2015-05-01' ORDER BY hits DESC LIMIT 10
SELECT * FROM stackoverflow.search_clickhouse_stackoverflow
SELECT * FROM stackoverflow.search_stackoverflow(text = 'ClickHouse MergeTree') ORDER BY Score DESC LIMIT 1
SHOW TABLES FROM imdb
SELECT m.name AS name, g.genre AS genre FROM imdb.movies AS m INNER JOIN imdb.genres AS g ON m.id = g.movie_id ORDER BY m.year DESC, m.name ASC, g.genre ASC LIMIT 10
SELECT m.name FROM imdb.movies AS m LEFT JOIN imdb.genres AS g ON m.id = g.movie_id WHERE g.movie_id = 0 ORDER BY m.year DESC, m.name ASC LIMIT 10
SELECT m.name, m.id, g.movie_id, g.genre FROM imdb.movies AS m CROSS JOIN imdb.genres AS g LIMIT 10
SELECT m.name, g.genre FROM imdb.movies AS m CROSS JOIN imdb.genres AS g WHERE m.id = g.movie_id ORDER BY m.year DESC, m.name ASC LIMIT 10
EXPLAIN SYNTAX SELECT m.name AS name, g.genre AS genre FROM imdb.movies AS m CROSS JOIN imdb.genres AS g WHERE m.id = g.movie_id ORDER BY m.year DESC, m.name ASC, g.genre ASC LIMIT 10
SELECT a.first_name, a.last_name FROM imdb.actors AS a SEMI LEFT JOIN imdb.roles AS r ON a.id = r.actor_id WHERE toYear(created_at) = '2023' ORDER BY id ASC LIMIT 10
SELECT m.name FROM imdb.movies AS m ANTI LEFT JOIN imdb.genres AS g ON m.id = g.movie_id ORDER BY year DESC, name ASC LIMIT 10
WITH left_table AS (SELECT * FROM VALUES('c UInt32', 1, 2, 3)), right_table AS (SELECT * FROM VALUES('c UInt32', 2, 2, 3, 3, 4)) SELECT l.c AS l_c, r.c AS r_c FROM left_table AS l ANY LEFT JOIN right_table AS r ON l.c = r.c
WITH left_table AS (SELECT * FROM VALUES('c UInt32', 1, 2, 3)), right_table AS (SELECT * FROM VALUES('c UInt32', 2, 2, 3, 3, 4)) SELECT l.c AS l_c, r.c AS r_c FROM left_table AS l ANY RIGHT JOIN right_table AS r ON l.c = r.c
WITH left_table AS (SELECT * FROM VALUES('c UInt32', 1, 2, 3)), right_table AS (SELECT * FROM VALUES('c UInt32', 2, 2, 3, 3, 4)) SELECT l.c AS l_c, r.c AS r_c FROM left_table AS l ANY INNER JOIN right_table AS r ON l.c = r.c
SELECT * FROM system.formats
SELECT * FROM system.table_engines
SELECT * FROM system.functions WHERE origin = 'System'
WITH both AS (SELECT name, 'Table function' AS category FROM system.table_functions UNION ALL SELECT name, 'Table engine' AS category FROM system.table_engines) SELECT * FROM both WHERE (NOT (name ILIKE '%mergeTree%')) AND (NOT (name ILIKE '%view%')) AND (NOT (name ILIKE '%values%')) AND (NOT (name ILIKE '%zeros%')) AND (NOT (name ILIKE '%cosn%')) AND (NOT (name ILIKE '%cosn%')) AND (NOT (name ILIKE '%buffer%')) AND (NOT (name ILIKE '%replica%')) AND (NOT (name ILIKE '%distributed%')) AND (NOT (name ILIKE '%json%')) AND (NOT (name ILIKE '%random%')) AND (NOT (name ILIKE '%merge%')) AND (NOT (name ILIKE '%null%')) AND (NOT (name ILIKE '%numbers%')) AND (NOT (name ILIKE '%oss%')) AND (NOT (name IN ['cluster', 'format', 'input', 'Join', 'KeeperMap', 'Log', 'Memory', 'Set', 'StripeLog', 'TinyLog'])) ORDER BY lower(name) ASC
SELECT station, sum(entries_change) AS total_entries, formatReadableQuantity(total_entries) AS total_entries_read FROM mta.subway_transits_2014_2022_v2 WHERE toYear(date_time) = '2018' GROUP BY station ORDER BY sum(entries_change) DESC LIMIT 10
SELECT station, toYear(date_time) AS year, sum(entries_change) AS total_entries FROM mta.subway_transits_2014_2022_v2 WHERE station IN (SELECT station FROM mta.subway_transits_2014_2022_v2 GROUP BY station ORDER BY sum(entries_change) DESC LIMIT 10) GROUP BY year, station ORDER BY year ASC
SELECT toStartOfWeek(transit_timestamp) AS week, 'weekday' AS period, sum(ridership) AS total FROM mta.transit_data WHERE toDayOfWeek(transit_timestamp) <= 5 GROUP BY week ORDER BY week ASC UNION ALL SELECT toStartOfWeek(transit_timestamp) AS week, 'weekend' AS period, sum(ridership) AS total FROM mta.transit_data WHERE toDayOfWeek(transit_timestamp) > 5 GROUP BY week ORDER BY week ASC
SELECT station_complex, toHour(hour_of_day) AS hour, CAST(avg(total_entries), 'UInt64') AS avg_entries FROM (SELECT toStartOfHour(transit_timestamp) AS hour_of_day, station_complex, sum(ridership) AS total_entries FROM mta.transit_data WHERE toDayOfWeek(transit_timestamp) <= 5 GROUP BY station_complex, hour_of_day) GROUP BY hour, station_complex ORDER BY hour ASC, avg_entries DESC LIMIT 3 BY hour
SELECT created_at, text FROM twitter.twitter WHERE tupleElement(user, 'screen_name') = 'elonmusk' ORDER BY created_at ASC
SELECT toStartOfYear(date) AS year, quantileExact(0.99)(tempAvg / 10) AS `99th_avg_temp`, dictGet(country.country_iso_codes, 'name', code) AS country FROM noaa.noaa_v2 WHERE (date > '1990-01-01') AND (code IN ('FR', 'UK', 'IN', 'NZ', 'SP', 'US')) GROUP BY year, substring(station_id, 1, 2) AS code HAVING `99th_avg_temp` > 0 ORDER BY country ASC, year ASC LIMIT 100000
WITH (SELECT max(upload_time) AS max_date FROM pypi.projects) AS max_date SELECT release_month AS x, name AS y, uniqExact(version) AS z FROM pypi.projects WHERE (name IN ({packages:Array(String) })) AND (toStartOfMonth(upload_time) > toStartOfMonth(max_date - toIntervalMonth(6))) GROUP BY name, toMonth(upload_time) AS month, formatDateTime(upload_time, '%b') AS release_month ORDER BY month ASC LIMIT 30
SELECT project, sum(count) AS c FROM pypi.pypi_downloads GROUP BY project ORDER BY c DESC LIMIT 5
SELECT formatReadableQuantity(sum(count)) AS total, uniqExact(project) AS projects FROM pypi.pypi_downloads
SELECT event, hour_of_day, sum(count) AS count FROM bluesky.events_per_hour_of_day WHERE event IN ['post', 'repost', 'like'] GROUP BY event, hour_of_day ORDER BY hour_of_day ASC
SELECT handle, sum(reposts) AS reposts FROM bluesky.reposts_per_user AS rpu INNER JOIN bluesky.handle_per_user AS hpu ON rpu.did = hpu.did GROUP BY ALL ORDER BY reposts DESC LIMIT 10
SELECT handle, sum(likes) AS likes FROM bluesky.likes_per_user AS lpu INNER JOIN bluesky.handle_per_user AS hpu ON lpu.did = hpu.did GROUP BY ALL ORDER BY likes DESC LIMIT 10
SELECT language, sum(posts) AS posts FROM bluesky.posts_per_language GROUP BY language ORDER BY posts DESC LIMIT 10
WITH top_liked_cids AS (SELECT cid, sum(reposts) AS reposts FROM bluesky.reposts_per_post GROUP BY cid ORDER BY reposts DESC LIMIT 10) SELECT t1.reposts, t2.text FROM top_liked_cids AS t1 LEFT JOIN (SELECT * FROM bluesky.cid_to_text WHERE cid IN (SELECT cid FROM top_liked_cids)) AS t2 ON t1.cid = t2.cid
WITH top_liked_cids AS (SELECT cid, SUM(likes) AS likes FROM bluesky.likes_per_post GROUP BY cid ORDER BY likes DESC LIMIT 10) SELECT t1.likes, t2.text FROM top_liked_cids AS t1 LEFT JOIN (SELECT * FROM bluesky.cid_to_text WHERE cid IN (SELECT cid FROM top_liked_cids)) AS t2 ON t1.cid = t2.cid
WITH top_liked_cids AS (SELECT cid, SUM(likes) AS likes FROM bluesky.likes_per_post_about_clickhouse GROUP BY cid ORDER BY likes DESC LIMIT 3) SELECT t1.likes, t2.text FROM top_liked_cids AS t1 LEFT JOIN (SELECT * FROM bluesky.cid_to_text WHERE cid IN (SELECT cid FROM top_liked_cids)) AS t2 ON t1.cid = t2.cid
SELECT collection, sum(posts) AS posts FROM bluesky.top_event_types GROUP BY collection ORDER BY posts DESC
SELECT collection, uniqMerge(users) AS users FROM bluesky.top_event_types GROUP BY collection ORDER BY users DESC
SELECT collection, sum(posts) AS posts, uniqMerge(users) AS users FROM bluesky.top_event_types GROUP BY collection ORDER BY posts DESC
SELECT count() FROM bluesky.bluesky
SELECT toDateTime(toStartOfInterval(TimestampTime, toIntervalSecond(60))) AS time, SeverityText, count() AS count FROM otel.otel_logs WHERE time >= (NOW() - toIntervalHour(1)) GROUP BY SeverityText, time ORDER BY time ASC
SELECT Timestamp AS log_time, Body FROM otel.otel_logs WHERE TimestampTime >= (NOW() - toIntervalHour(1)) LIMIT 100
SELECT Timestamp AS log_time, Body FROM otel.otel_logs WHERE (ServiceName = 'recommendationservice') AND (TimestampTime >= (NOW() - toIntervalHour(1))) LIMIT 100
SELECT Timestamp AS log_time, Body, LogAttributes['productId'] FROM otel.otel_logs WHERE ((LogAttributes['productId']) = '9SIQT8TOJO') AND (TimestampTime >= (NOW() - toIntervalHour(1))) LIMIT 10
SELECT Timestamp AS log_time, Body FROM otel.otel_logs WHERE hasToken(Body, 'otelcol') AND (TimestampTime >= (NOW() - toIntervalHour(1))) LIMIT 100
SELECT Timestamp AS log_time, Body FROM otel.otel_logs WHERE (Body LIKE '%binoculars%') AND (TimestampTime >= (NOW() - toIntervalHour(1))) LIMIT 100
SELECT Timestamp, TraceId, SpanId, ParentSpanId, SpanName, SpanKind, ServiceName, Duration, StatusCode, StatusMessage, toString(SpanAttributes), toString(ResourceAttributes), toString(Events.Name), toString(Links.TraceId) FROM otel.otel_traces WHERE (ServiceName = 'recommendationservice') AND ((SpanAttributes['rpc.service']) = 'oteldemo.ProductCatalogService') AND (Timestamp >= (NOW() - toIntervalHour(1))) LIMIT 100
SELECT Timestamp, TraceId, SpanId, ParentSpanId, SpanName, SpanKind, ServiceName, Duration, StatusCode, StatusMessage, toString(SpanAttributes), toString(ResourceAttributes), toString(Events.Name), toString(Links.TraceId) FROM otel.otel_traces WHERE (ServiceName = 'recommendationservice') AND (StatusCode = 'STATUS_CODE_ERROR') AND (Timestamp >= (NOW() - toIntervalHour(1))) LIMIT 100
SELECT Timestamp, TraceId, SpanId, ParentSpanId, SpanName, SpanKind, ServiceName, Duration, StatusCode, StatusMessage, toString(SpanAttributes), toString(ResourceAttributes), toString(Events.Name), toString(Links.TraceId) FROM otel.otel_traces WHERE (ServiceName = 'recommendationservice') AND (Duration > (1 * 1000.)) AND (Timestamp >= (NOW() - toIntervalHour(1))) LIMIT 100
SELECT count() FROM otel.otel_logs
SELECT count() FROM otel.otel_traces
SELECT name, date, total_downloads FROM rubygems.daily_downloads WHERE name ILIKE 'ClickHouse%' ORDER BY date ASC
SELECT name, max(total_downloads) AS total_downloads FROM rubygems.daily_downloads GROUP BY name ORDER BY total_downloads DESC LIMIT 5
WITH (SELECT max(created_at) AS max_date FROM rubygems.versions) AS max_date SELECT release_month AS x, name AS y, uniqExact(number) AS z FROM rubygems.versions WHERE (rubygem_id IN (SELECT id FROM rubygems.rubygems WHERE name IN ['bundler', 'aws-sdk-core', 'aws-sigv4', 'jmespath', 'aws-partitions'])) AND (toStartOfMonth(created_at) > toStartOfMonth(max_date - toIntervalMonth(6))) GROUP BY dictGet(rubygems.id_to_name, 'name', rubygem_id) AS name, toMonth(created_at) AS month, formatDateTime(created_at, '%b') AS release_month ORDER BY month ASC LIMIT 30
WITH (SELECT max(max_date) FROM rubygems.gems_downloads_max_min) AS max_date SELECT gem, sum(count) AS c FROM rubygems.downloads_per_day WHERE gem IN (SELECT name FROM rubygems.gems_downloads_max_min GROUP BY name HAVING min(min_date) >= (max_date - toIntervalMonth(3))) GROUP BY gem ORDER BY c DESC LIMIT 7 SETTINGS enable_analyzer = 0
WITH (SELECT max(max_date) FROM rubygems.gems_downloads_max_min) AS max_date, percentage_increases AS (SELECT name, sum(daily_downloads) AS c, toStartOfMonth(date) AS month, any(c) OVER (PARTITION BY name ORDER BY month ASC ROWS BETWEEN 1 PRECEDING AND 1 PRECEDING) AS previous, if(previous > 0, (c - previous) / previous, 0) AS percent_increase FROM rubygems.daily_downloads WHERE ((month > (toStartOfMonth(max_date) - toIntervalMonth(6))) AND (month <= toStartOfMonth(max_date))) AND (name IN (SELECT name FROM rubygems.daily_downloads GROUP BY name HAVING max(total_downloads) > 100000)) GROUP BY name, month ORDER BY name ASC, month ASC) SELECT formatDateTime(month, '%b') AS x, name AS y, c AS z FROM percentage_increases WHERE name IN (SELECT name FROM percentage_increases GROUP BY name ORDER BY max(percent_increase) DESC LIMIT 5) ORDER BY month DESC, name ASC
SELECT date, sum(count) AS total_downloads FROM rubygems.downloads_per_day WHERE gem = 'bundler' GROUP BY date ORDER BY date ASC
SELECT toStartOfHour(timestamp) AS hour, count() AS total_downloads FROM rubygems.downloads WHERE (gem = 'bundler') AND (timestamp > (now() - toIntervalDay(2))) GROUP BY hour ORDER BY hour ASC
WITH top_versions AS (SELECT user_agent.ruby FROM rubygems.downloads WHERE ((timestamp >= '2025-01-01') AND (timestamp <= '2025-04-03')) AND (gem = 'bundler') GROUP BY user_agent.ruby ORDER BY count() DESC LIMIT 10) SELECT if(user_agent.ruby IN (top_versions), user_agent.ruby, 'other') AS ruby_version, toStartOfHour(timestamp) AS hour, count() AS downloads FROM rubygems.downloads WHERE ((timestamp >= '2025-01-01') AND (timestamp <= '2025-04-03')) AND (gem = 'bundler') AND (ruby_version != '') GROUP BY hour, ruby_version ORDER BY hour DESC, ruby_version ASC
WITH systems AS (SELECT user_agent.platform.os FROM rubygems.downloads WHERE ((timestamp >= '2025-01-01') AND (timestamp <= '2025-04-03')) AND (gem = 'bundler') AND (user_agent.platform.os NOT IN ('', 'unknown')) GROUP BY user_agent.platform.os ORDER BY count() DESC LIMIT 5) SELECT user_agent.platform.os AS name, toStartOfHour(timestamp) AS hour, count() AS total_downloads FROM rubygems.downloads WHERE ((timestamp >= '2025-01-01') AND (timestamp <= '2025-04-03')) AND (gem = 'bundler') AND (user_agent.platform.os IN (systems)) GROUP BY name, hour ORDER BY hour ASC, name DESC
SELECT canonical_number FROM rubygems.versions WHERE rubygem_id = dictGet(rubygems.name_to_id, 'id', 'bundler') ORDER BY arrayMap(x -> toUInt8OrDefault(x, 0), splitByChar('.', canonical_number)) DESC LIMIT 1
WITH (SELECT canonical_number FROM rubygems.versions WHERE rubygem_id = dictGet(rubygems.name_to_id, 'id', 'bundler') ORDER BY arrayMap(x -> toUInt8OrDefault(x, 0), splitByChar('.', canonical_number)) DESC LIMIT 1) AS latest_version SELECT toStartOfWeek(timestamp) AS week, count() AS downloads FROM rubygems.downloads WHERE (gem = 'bundler') AND (version = latest_version) GROUP BY week ORDER BY week ASC
SELECT author, countIf(line_type = 'Code') AS code_lines, countIf((line_type = 'Comment') OR (line_type = 'Punct')) AS comments, code_lines / (comments + code_lines) AS ratio_code, toStartOfWeek(time) AS week FROM git.clickhouse_line_changes GROUP BY time, author ORDER BY author ASC, time ASC LIMIT 10
SELECT URLDomain, groupArrayDistinct(OS) AS distinct_os_codes FROM metrica.hits_v1 WHERE URLDomain != '' GROUP BY URLDomain ORDER BY URLDomain ASC LIMIT 20
SELECT toStartOfMonth(date) AS month, formatReadableQuantity(sumIf(volume, price > open)) AS volume_on_up_days, formatReadableQuantity(sumIf(volume, price < open)) AS volume_on_down_days, formatReadableQuantity(sumIf(volume, price = open)) AS volume_on_neutral_days, formatReadableQuantity(sum(volume)) AS total_volume FROM stock.stock WHERE (date >= '2002-01-01') AND (date <= '2002-12-31') GROUP BY month ORDER BY month ASC
SELECT toHour(EventTime) AS hour_of_day, sumForEach([IsMobile = 0, IsMobile = 1]) AS device_counts FROM metrica.hits GROUP BY hour_of_day ORDER BY hour_of_day ASC
